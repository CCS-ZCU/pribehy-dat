{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CCS-ZCU/pribehy-dat/blob/master/scripts/http.ipynb)\n",
    "\n",
    "Tento soubor je součástí sestavy elektronických studijních opor [Příběhy dat: Výpočetní přístupy ke studiu kultury a společnosti](https://github.com/CCS-ZCU/pribehy-dat/tree/master). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# HTTP: Dotazování webu\n",
    "\n",
    "### Úvod a cíle kapitoly\n",
    "\n",
    "V této kapitole se podíváme na získání dat z různých internetových platforem.  Webový prohlížeč je jen jeden ze způsobů, jak využívat internet. Mnohé aplikace, které máme v našich počítačích i chtrých telefonech, získávají z internetu data, aniž by webový prohlížeč jakkoli vstupoval do hry. Python a Jupyter notebooky mohou být využitý jako takováto aplikace. K mnohým datům, která jsou dostupná na internetu, se tak lze dostat přímo z našeho Python prostředí, aniž bychom museli data nejprve stahovat a poté do Pythonu načítat ve formě souborů.\n",
    "\n",
    "Tato data se z webu získávají typicky pomocí protokolu HTTP (Hypertext Transfer Protocol): Aplikace vznese dotaz v podobě konkrétní URL adresy, na který webovy server podá odpověď ve formě dat. Tento proces se vlastně děje i na pozadí našeho prohlížeče: Přes zadanou URL adresu doazujeme určitý webový server, který našemu prohlížeči jako odpověď vrátí tzv. zdrojový kód stránky ve formátu HTML. Vyzkoušejme si to nyní na několika příkladech.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Jako první příklad nám mohou posloužit webové stránky hesel ze Slovníku českých filozofů dostupná z tohoto rozcestníku: https://filozofie.phil.muni.cz/vyzkum/publikace/scf/abecedni-seznam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:03:45.253823Z",
     "start_time": "2024-01-19T12:03:42.542276Z"
    },
    "execution_time": 1
   },
   "outputs": [],
   "source": [
    "# naimportujeme si několik knihoven\n",
    "import requests # python knihovna pro vznášení HTTP dotazů\n",
    "from bs4 import BeautifulSoup # python knihovna pro práci s daty ve formátu html či xml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:10:14.456980Z",
     "start_time": "2024-01-19T12:10:14.455458Z"
    },
    "execution_time": 2
   },
   "outputs": [],
   "source": [
    "# url adresa hesla věnovaného Jiřímu Fialovi:\n",
    "url = \"https://www.phil.muni.cz/fil/scf/komplet/fiala.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:10:14.829558Z",
     "start_time": "2024-01-19T12:10:14.772771Z"
    },
    "execution_time": 3
   },
   "outputs": [],
   "source": [
    "# na tuto webovou adresu nyní vzneseme dotaz pomocí knihovny requests\n",
    "# odpověď si uložíme do proměnné `resp`:\n",
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:10:14.937350Z",
     "start_time": "2024-01-19T12:10:14.930900Z"
    },
    "execution_time": 4
   },
   "outputs": [],
   "source": [
    "# odpověď si vypíšeme\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pokud máme funkční připojení k internetu a a validní URL adresu, odpověď by měla být: \"<Response [200]>\".\n",
    "Avšak v případě, že jsme například zvolili neexistující URL, odpověď bude jiná. Vyzkoušejme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:10:16.517762Z",
     "start_time": "2024-01-19T12:10:16.446014Z"
    },
    "execution_time": 5
   },
   "outputs": [],
   "source": [
    "url = \"https://www.phil.muni.cz/fil/scf/komplet/plato.html\"\n",
    "resp_test = requests.get(url)\n",
    "resp_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vraťme se však zpět k naší odpovědi (objektu `resp`) z funkční URL adresy. Tento objekt totiž v sobě nese mnohem více, než jen informaci o tom, zda jsme obdrželi validní odpověď. Tato další data se skrývají zejména pod atributem `.text` (či `.content`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:22:14.744659Z",
     "start_time": "2024-01-19T12:22:14.681292Z"
    },
    "execution_time": 6
   },
   "outputs": [],
   "source": [
    "url = \"https://www.phil.muni.cz/fil/scf/komplet/fiala.html\"\n",
    "resp = requests.get(url)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Co zde vidíme? Jedná se o zdrojový kód příslušné webové. Přesně z těchto dat náš prohlížeč vychází, když nám prezentuje vybranou webovou stránku. V tomto kroku je daný kód zapouzdřený jako proměnná typu string. Všimněme si, že zde máme problém se znakovou sadou: např. \"pøekladù\" namísto \"překladů\". Tento nedostatek však rychle napravíme a na text se podíváma ještě jednou: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:25:15.682520Z",
     "start_time": "2024-01-19T12:25:15.667419Z"
    },
    "execution_time": 7
   },
   "outputs": [],
   "source": [
    "resp.encoding = 'windows-1250' # volba znakové sady\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Nyní je již vše správně. Tato data v sobě však nesou více než prostý text - jsou ve formátu HTML, sestávající z mnoha tagů, které určují kde začíná a končí řádka, vyznačují další hypertextové odkazy apod. Nyní proto použijeme knihovny `BeautifulSoup`, abychom tento text interpretovali (parsovali) jako HTML kód, ve kterém se lze pohybovat jako v jakémsi stromu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:30:08.941189Z",
     "start_time": "2024-01-19T12:30:08.918282Z"
    },
    "execution_time": 8
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Objekt soup v sobě skrývá navigovatelnou stromovou strukturu celé html stránky. Můžeme zde nyní přistupovat k datům z jednotlivých tagů případně je i měnit. Názorné příklady jsou k dispozici v dokumentaci knihovny v sekci \"Quick start\". \n",
    "\n",
    "Například pod tagem `title` se skrývá název příslušné webové stránky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T12:30:58.540497Z",
     "start_time": "2024-01-19T12:30:58.521127Z"
    },
    "execution_time": 9
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:04:37.267392Z",
     "start_time": "2024-01-20T09:04:37.249713Z"
    },
    "execution_time": 10
   },
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pokud nás zajímá pouze textový obsah daného tagu, příkaz ještě doplníme o atribut `string` nebo metodu `get_text()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:04:40.002172Z",
     "start_time": "2024-01-20T09:04:39.994521Z"
    },
    "execution_time": 11
   },
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Po troše experimentování a prozkoumávání můžeme například zjistit, že datum narození a úmrtí se v dané struktuře nachází zde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:06:15.770091Z",
     "start_time": "2024-01-20T09:06:15.767699Z"
    },
    "execution_time": 12
   },
   "outputs": [],
   "source": [
    "soup.body.find_all(\"p\")[2].find_all(\"strong\")[0].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:06:23.373469Z",
     "start_time": "2024-01-20T09:06:23.356146Z"
    },
    "execution_time": 13
   },
   "outputs": [],
   "source": [
    "soup.body.find_all(\"p\")[2].find_all(\"strong\")[1].string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To jsou velice zajímavá a cenná metadata. Je stejná struktura zachována i na dalších stránkách ve slovníku? To nyní prověříme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T10:04:30.923148Z",
     "start_time": "2024-01-20T10:04:30.809008Z"
    },
    "execution_time": 14
   },
   "outputs": [],
   "source": [
    "url = \"https://www.phil.muni.cz/fil/scf/komplet/machjs.html\"\n",
    "resp = requests.get(url)\n",
    "resp.encoding = 'windows-1250'\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "soup.title.string # vypíšeme název html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T10:04:31.413356Z",
     "start_time": "2024-01-20T10:04:31.409190Z"
    },
    "execution_time": 15
   },
   "outputs": [],
   "source": [
    "soup.body.find_all(\"p\")[2].find_all(\"strong\")[0].get_text() # pokusíme se nalézt datum a místo narození"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T10:04:34.870328Z",
     "start_time": "2024-01-20T10:04:34.846729Z"
    },
    "execution_time": 16
   },
   "outputs": [],
   "source": [
    "soup.body.find_all(\"p\")[2].find_all(\"strong\")[1].get_text() # pokusíme se nalézt datum a místo úmrtí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution_time": 17
   },
   "outputs": [],
   "source": [
    "# Tato buňka slouží ke kontrole průchodu tímto cvičením. \n",
    "# Pokud toto cvičení plníte v rámci svých studijních povinností na ZČU, buňku spusťte a držte se instrukcí.\n",
    "exec(requests.get(\"https://sciencedata.dk/shared/856b0a7402aa7c7258186a8bdb329bd3?download\").text)\n",
    "kontrola_pruchodu(ntb=\"http\", arg1=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Práce s mnoha webovými stránkami najednou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Webové stránky Slovníku českých filozofů mají abecední rozcestník: https://filozofie.phil.muni.cz/vyzkum/publikace/scf/abecedni-seznam. Při ohledání zdrojového kódu této stránky se ukazuje, že obsahuje URL adresy všech hesel ve slovníku. Srdce datového analytika zaplesá: To znamená, že můžeme jednu po druhé procházet všechny dané webové stránky a získat z nich data, která nás zajímají, například informace o datech a místech narození a úmrtí všech zahrnutých osobností. \n",
    "\n",
    "Nejprve budeme postupovat stejně jako výše: Pomocí `requests` získáme objekt `resp`, jehož datový obsah v podobě zdrojového kódu příslušné webové adresy naparsujeme pomocí `BeautifulSoup()` do navigovatelného stromu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:22:44.368244Z",
     "start_time": "2024-01-20T09:22:43.489680Z"
    },
    "execution_time": 18
   },
   "outputs": [],
   "source": [
    "url = \"https://filozofie.phil.muni.cz/vyzkum/publikace/scf/abecedni-seznam\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Nyní pomocí cyklu FOR projedeme všechny tagy `a` (stanardní tag pro hypertextový odkaz). Pokud se v hodnotě atributu \"href\" tohoto tagu nachází URL adresa začínající stejně jako URL adresy jednotlivých hesel ve slovníků, extrahujeme tuto adresu a přidáme ji na seznam `filtered_hrefs`. (Ve zdrojovém kódu se může vyskytovat mnoho dalších URL adres, odkazujících např. kamsi na web Masarykovy univerzity, ty nás ale nyní nezajímají, proto tato podmínka.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:27:46.048245Z",
     "start_time": "2024-01-20T09:27:46.039222Z"
    },
    "execution_time": 19
   },
   "outputs": [],
   "source": [
    "filtered_hrefs = []\n",
    "\n",
    "for a_tag in soup.find_all('a'):\n",
    "    href = a_tag.get('href')    # Extract 'href' attribute value.\n",
    "    if href and href.startswith('http://www.phil.muni.cz/fil/scf/komplet/'):   # condition\n",
    "        filtered_hrefs.append(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "vypišme si prvních 10 URL adres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T09:57:41.014536Z",
     "start_time": "2024-01-20T09:57:41.009704Z"
    },
    "execution_time": 20
   },
   "outputs": [],
   "source": [
    "filtered_hrefs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Nyní vytvoříme cyklus FOR, v rámci kterého získáme zdrojový kód HTML stránky každé z těchto URL adres pomocí `requests`, zpracujeme jej pomocí `BeautifulSoup` a pokusíme se získat data se jmény jednotlivých filozofů a o místech a datech narození a úmrtí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T18:28:33.574394Z",
     "start_time": "2024-01-20T18:27:15.722278Z"
    },
    "execution_time": 21
   },
   "outputs": [],
   "source": [
    "failed = []\n",
    "slovnik_data = []\n",
    "for url in filtered_hrefs[:10]:\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        resp.encoding = 'windows-1250'\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        title = soup.title.string\n",
    "        birth = soup.body.find_all(\"p\")[2].find_all(\"strong\")[0].string\n",
    "        try:\n",
    "            death = soup.body.find_all(\"p\")[2].find_all(\"strong\")[1].string\n",
    "        except:\n",
    "            death = None\n",
    "        if \"*\" not in str(birth):\n",
    "            birth = None\n",
    "        if \"†\" not in str(death):\n",
    "            death = None\n",
    "        slovnik_data.append({\"url\" : url, \"name\" : title, \"birth\" : birth, \"death\" : death})\n",
    "    except:\n",
    "        failed.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Z dat, která jsme takto získali, vytvoříme velice snadno tabulku, respektivě objekt typu `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T20:09:17.577291Z",
     "start_time": "2024-01-20T20:09:17.536760Z"
    },
    "execution_time": 22
   },
   "outputs": [],
   "source": [
    "slovnik_df = pd.DataFrame(slovnik_data) # vytvoříme dataframe\n",
    "slovnik_df = slovnik_df.replace(to_replace=r'\\r\\n', value='', regex=True) # drobné čičtění \n",
    "slovnik_df # dataframe si vypíšeme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vidíme relativně pěkně naformátovanou tabulku se čtyřmi sloupci. Některé hodnoty jsou prázdné (`None`), například ve sloupci \"death\" v případě, že se jedná o žijícího autora. V jiných případech se zdá, že některá hesla jsou naformátovaná odlišně.\n",
    "\n",
    " Z praktických důvodů jsme se však omezili pouze na 10 prvních hesel. Dropnou úpravou (odstraněním \"[:10\"]) však lze skript snadno přenastavit tak, aby se aplikoval na všechny URL adresy na seznamu. Tomu se však nyní společně vyhneme, abychom příslušnou webovou doménu zbytečně nezavalovali tisíci HTTP dotazy. Na místo toho si tato kompletní data načteme z místa, kam jsem je dopředu uložil a vypíšeme si první 20 položek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T20:11:35.804362Z",
     "start_time": "2024-01-20T20:11:35.767200Z"
    },
    "execution_time": 23
   },
   "outputs": [],
   "source": [
    "slovnik_df.to_csv(\"../data/slovnik_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-20T18:38:52.728741Z",
     "start_time": "2024-01-20T18:38:52.209770Z"
    },
    "execution_time": 24
   },
   "outputs": [],
   "source": [
    "slovnik_df = pd.read_csv(\"https://raw.githubusercontent.com/CCS-ZCU/pribehy-dat/master/data/slovnik_df.csv\")\n",
    "slovnik_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution_time": 25
   },
   "outputs": [],
   "source": [
    "# Tato buňka slouží ke kontrole průchodu tímto cvičením. \n",
    "# Pokud toto cvičení plníte v rámci svých studijních povinností na ZČU, buňku spusťte a držte se instrukcí.\n",
    "kontrola_pruchodu(ntb=\"http\", arg1=\"http2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "V některé z dalších kapitol se k těmto datům vrátíme a budeme pracovat se sloupci \"birth\" a \"death\", které obsahují cenné časoprostorové informace. Tyto informace nyní nejsou v podobě vhodné pro kvantitativní analýzu. My si však ukážeme, jak je přetavit do podoby, aby pro tuto analýzu byla tato dato vhodná.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Je nasnadě, že podobný přístup lze aplikovat na mnohé webové stránky, a to zvláště tehdy, kdy se jedná o velké množství podobně naformátovaných stránek. Často to je jediný přístup, jak se k podobným datům dostat. Této metodě se také říká \"web scraping\" a je někdy problematická z etického hlediska. Některé webové stránky výslovně zakazují, aby data, která se na nich nacházejí, byla dolována podobným způsobem. Někdy je to motivováno obavou z přetížení příslušného webového serveru mnoha dotazy, jindy spíše s ohledem na autorství. Často se však zdá, že tvůrce daných webových stránek vůbec nenapadlo, že by jejich dat někdo mohl chtít využívat tímto způsobem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution_time": 26
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
