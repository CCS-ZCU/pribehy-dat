{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayU0ucI1UYjq"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CCS-ZCU/pribehy-dat/blob/master/scripts/nlp.ipynb)\n",
    "\n",
    "# NLP: Zpracování přirozeného jazyka\n",
    "\n",
    "**autor**: *Vojtěch Kaše* (kase@ff.zcu.cz)\n",
    "\n",
    "[![](https://ccs.zcu.cz/wp-content/uploads/2021/10/cropped-ccs-logo_black_space_240x240.png)](https://ccs.zcu.cz)\n",
    "\n",
    "## Úvod a cíle kapitoly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qReidPvUbhS"
   },
   "source": [
    "Cílem tohoto cvičení je provést základní kvantitativní textovou analýzu některého digitalizovaného dokumentu z **Archivu Jana Patočky** ([AJP](https://archiv.janpatocka.cz/items/browse?tags=fulltext)). Omezíme se však pouze na dokumenty, u kterých je dostupný digitální přepis (tzv. fulltext). Tj. URL adresa, kterou hledáme, je adresa jakéhokoliv námi vybraného dokumentu z daného archivu pro který je dostupný přepis. Pro zvládnutí cvičení není potřeba nic více než na několika místech ručně nahradit jeden řetězec znaků za jiný pomocí Ctrl+C a Ctrl+V a ve správném pořadí spustit jednotlivé buňky pomocí ikony \"play\" či klávesové zkratky Shift+Enter.\n",
    "\n",
    "Doklad o provedení cvičení bude nahrání Vámi upravené kopie jupyter notebooku ve formátu PDF do odevzdávárny v moodlu (viz níže).\n",
    "\n",
    "Následující buňka je první klíčovou buňkou pro naše cvičení a  je potřeba ji spustit předtím, než buňky, které následují, neboť ty staví na funkcích, které v této buňce do aktuálního jupyter notebooku importujeme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cvičení"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 1,
    "id": "fxzyIjpDCU2l",
    "outputId": "bee5fa7b-6936-4965-9a86-3b66a663739a"
   },
   "outputs": [],
   "source": [
    "# naše první buňka slouží k tomu, abychom do aktuálního GoogleColab skriptu\n",
    "# importovali určité dodatečné balíčky (či knihovny) s funkcemi,\n",
    "# které nejsou v \"základní výbavě\" Pythonu. Některé knihovny budeme muset dokonce nainstalovat\n",
    "\n",
    "import requests\n",
    "from urllib.request import urlopen # pro práci w webovými adresami\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup # pro práci s webovými stránkami ve formátu html\n",
    "import json\n",
    "import re # pro práci s regulérními výrazy\n",
    "import pandas as pd # pro práci s tabulkami ve formátu dataframe\n",
    "import nltk # modul pro práci s textovými daty\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')\n",
    "import matplotlib.pyplot as plt # modul pro vytváření grafů\n",
    "import numpy as np # modul pro pokročilejší matematické operac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQMW7GIgiLep"
   },
   "source": [
    "Váš hlavní úkol je spojen s buňkou níže. V ní je potřeba nahradit obsah proměnné \"url\", tj. **vyměnit webovou adresu jednoho dokumentu z AJP za adresu jiného dokumentu z téhož archivu**.  Pozor, že webová adresa musí být uvnitř uvozovek. Aby se změna projevila, je třeba buňku nakonec spustit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution_time": 2,
    "id": "_wNGwo_kI8Ih"
   },
   "outputs": [],
   "source": [
    "url = \"https://archiv.janpatocka.cz/items/show/308\"\n",
    "web_text = urlopen(url).read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(web_text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution_time": 3,
    "id": "7G4gz4Ats6IM",
    "outputId": "b12035e8-c294-46ee-a4c1-cfeaeeefd2c1"
   },
   "outputs": [],
   "source": [
    "text_title = soup.find(\"div\", id=\"item_title\").get_text()\n",
    "text_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution_time": 4,
    "id": "9C9_3lxwtRN8",
    "outputId": "4a58139a-7df1-4d25-8361-cb5633102125"
   },
   "outputs": [],
   "source": [
    "[div for div in soup.find_all(\"div\", class_=\"col span_7_of_9\")][3].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 5,
    "id": "mkA4UEOhKG3e",
    "outputId": "86862efb-5167-4b43-db88-c6a5b3ad942d"
   },
   "outputs": [],
   "source": [
    "text_dokumentu = soup.find(\"div\", id=\"trans_full\").get_text()\n",
    "text_dokumentu = \" \".join(text_dokumentu.split())\n",
    "print(text_dokumentu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 6,
    "id": "5Buh6M5GOIS2",
    "outputId": "f562fdb6-d745-446d-8bb3-79f58edefd93"
   },
   "outputs": [],
   "source": [
    "# dokument jako list slov získáme pomocí funkce \"split()\"\n",
    "# uložíme si ho takto do nové proměnné \"pdf_string_list\"\n",
    "string_list = text_dokumentu.split()\n",
    "# tuto proměnnou si vypíšeme:\n",
    "string_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 7,
    "id": "f_8KiHMZ3cl0",
    "outputId": "6421edae-0c72-4f8c-cb62-e2f00ac34647"
   },
   "outputs": [],
   "source": [
    "### pomocí funkce \"len()\" spočítáme délku tohoto listu slov:\n",
    "len(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 8,
    "id": "HDMfBzJ9vF4e",
    "outputId": "67427868-4a42-4724-9edd-1d66d09ab2f7"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for n in range(0,3000):\n",
    "  try:\n",
    "    textdata = {}\n",
    "    id = str(n)\n",
    "    url = \"https://archiv.janpatocka.cz/items/show/\" + id\n",
    "    web_text = urlopen(url).read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(web_text, \"html.parser\")\n",
    "    text_title = soup.find(\"div\", id=\"item_title\").get_text()\n",
    "    date = [div for div in soup.find_all(\"div\", class_=\"col span_7_of_9\")][3].get_text()\n",
    "    text_dokumentu = soup.find(\"div\", id=\"trans_full\").get_text()\n",
    "    text_dokumentu = \" \".join(text_dokumentu.split())\n",
    "    print(id)\n",
    "    textdata[\"id\"] = id\n",
    "    textdata[\"title\"] = text_title\n",
    "    textdata[\"date\"] = date\n",
    "    textdata[\"rawtext\"] = text_dokumentu\n",
    "    data.append(textdata)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution_time": 9,
    "id": "v6jw1hS_xmtL",
    "outputId": "195cd3cc-b0b5-4715-beba-70a5ea1faa6f"
   },
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution_time": 10,
    "id": "OZY-PxYE6raf"
   },
   "outputs": [],
   "source": [
    "data_df.to_csv(\"my_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgIbCh5v4FR2"
   },
   "source": [
    "### Lematizace a postagging\n",
    "\n",
    "S textem článku, tak jak se nyní nachází v proměnné \"text_clanku\", bychom se ale při kvantitativní textové analýze stále příliš daleko nedostali. Čeština je totiž morfologicky velice bohatý jazyk. Chceme-li např. spočítat kolikrát se v textu objevuje sloveso \"mít\", s textem v aktuální podobě se příliš daleko nedstaneme. Zde potřebujeme na naše textová data aplikovat dvě další procedury:\n",
    "\n",
    "\n",
    "1.   lemmatizace, tj. převedení slov z textu do jejich základních tvarů (slovesa do infinitivu, podstatná jména do 1.pádu singuláru apod.)\n",
    "2.   POS-tagging (\"part-of-speech tags\"),  tj. určení slovních druhů a mluvnických kategorií\n",
    "\n",
    "Aplikace těchto procedur nám umožní získat data z hlediska kvantitativní textové analýzy výrazně zajímavější.\n",
    "\n",
    "V případě češtiny se můžeme v tomto případě opřít o webové nástroje z dílny Ústavu formální a aplikované lingivistiky FF UK, konkrétně o nástroj [Morphodita](http://ufal.mff.cuni.cz/morphodita).\n",
    "\n",
    "S našimi daty budeme postupovat tak, že z našeho jupyter notebooku vzneseme dotaz na webovou aplikaci MorphoDity,  a požádáme na dálku o lemmatizaci a postaging našich dat (tutoriál k webovému dotazování MorpohoDity se nachází [zde](http://lindat.mff.cuni.cz/services/morphodita/api-reference.php)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 11,
    "id": "TFA6qawWPTeF",
    "outputId": "bc7c059c-243c-4ff2-96a7-2c84e18cbe7d"
   },
   "outputs": [],
   "source": [
    "sentences = tokenize.sent_tokenize(text_dokumentu)\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution_time": 12,
    "id": "McpN2ONQO5Fs"
   },
   "outputs": [],
   "source": [
    "morfologicky_zpracovana_data = []\n",
    "# nejprve opět vzneseme webový dotaz s textem našeho článku\n",
    "for sentence in sentences:\n",
    "  url = 'http://lindat.mff.cuni.cz/services/morphodita/api/tag?data=' + quote(sentence)\n",
    "  resp = urlopen(url)\n",
    "  resp_content = resp.read().decode(\"utf-8\")\n",
    "  # výsledky dotazu (zpracovaná data) si uložíme do proměnné \"result\"\n",
    "  result = dict(json.loads(resp_content))[\"result\"]\n",
    "  # result má stromovou strukturu, kterou opět rozšifrujeme pomocí BeautifulSoup\n",
    "  soup = BeautifulSoup(result, 'html.parser')\n",
    "  # pro každé jednotlivé slovo si do jedné řádky vedle sebe vytahneme jeho (a) tvar jak je v textu, (b) lemmatizovanou podobu a (c) morfologické určení\n",
    "  # tato data budeme postupně přidávat do samostatné proměnné \"morfologicky_zpracovana_data\"\n",
    "  for token in soup.find_all(\"token\"):\n",
    "    morfologicky_zpracovana_data.append([token.get_text(), token[\"lemma\"].partition(\"-\")[0].partition(\"_\")[0], token[\"tag\"]])\n",
    "# z těchto dat si vytvoříme úhlednou tabulku ve formátu DataFrame (df):\n",
    "data_df = pd.DataFrame(morfologicky_zpracovana_data)\n",
    "# sloupce si pojmenujeme\n",
    "data_df.columns = [\"slovo_puvodni\", \"lemma\", \"POS-tag\"]\n",
    "# výsledný dataset si vypíšeme\n",
    "data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSvrljgi_P73"
   },
   "source": [
    "díky prvním písmenům třetího sloupce nyní víme, o jaký slovní druh se jedná:\n",
    "*   \"V...\" = sloveso\n",
    "*   \"N...\" = podstatné jméno\n",
    "*   \"A...\" = přídavné jméno\n",
    "\n",
    "Pro naše potřeby může bát zajímavé filtrovat tabulku tak, aby nám z textu zůstaly pouze tyto slovní druhy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "execution_time": 13,
    "id": "7myh2XlEFh6K",
    "outputId": "c36d50f5-33c1-43d1-9d5c-07a980b81730"
   },
   "outputs": [],
   "source": [
    "data_df_filtrovana = data_df[data_df[\"POS-tag\"].str.startswith((\"V\",\"N\",\"A\"))]\n",
    "data_df_filtrovana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZELHnjgDCobV"
   },
   "source": [
    "V této podobě může být již vcelku zajímavé podívat se na frekvence výskytů slov, resp. jejich lematizovaných tvarů. K tomu použijeme funkce z modulu \"nltk\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_time": 14,
    "id": "X4U0o6kLCn1b",
    "outputId": "e4cc6856-4c1b-4419-9f9e-3c169870344f"
   },
   "outputs": [],
   "source": [
    "# nejprve si z naší filtrované tabulky vyxtrahujeme lemmata samotná\n",
    "lemmata = data_df_filtrovana[\"lemma\"].tolist()\n",
    "# pro každý jednotlivý výraz necháme spočítat jeho počet výskytů\n",
    "lemmata_freq = nltk.FreqDist(lemmata)\n",
    "# vybereme např. 10 nejfrekventovanějších slov (rozumějme lemmatizovaných substantiv, adjektiv a sloves)\n",
    "lemmata_most_freq = lemmata_freq.most_common(10)\n",
    "print(lemmata_most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "execution_time": 15,
    "id": "DWv__cRRGjR6",
    "outputId": "8413317b-6492-46d3-9cdb-eccdd3084e44"
   },
   "outputs": [],
   "source": [
    "# kvůli horizontálnímu zobrazení prohodíme pořadí na našem listu\n",
    "lemmata_mostfreq = lemmata_most_freq\n",
    "lemmata_mostfreq.reverse()\n",
    "\n",
    "# pro potřeby grafu přiřadíme hodnoty jednotlivým osám\n",
    "height = [tup[1] for tup in lemmata_mostfreq]\n",
    "bars = [tup[0] for tup in lemmata_mostfreq]\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "plt.barh(y_pos, height)\n",
    "# graf si pojmenujeme a osu také\n",
    "plt.yticks(y_pos, bars)\n",
    "plt.xlabel('Frekvence výskytů')\n",
    "plt.title('Frekvence výskytů nejčastějších slov')\n",
    "# graf si zobrazíme\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVaZyxzwgK-o"
   },
   "source": [
    "Pokud jsme se bez chybové hlášky dostali až sem a pomocí buňky výše jsme úspěšně vykreslili graf nejfrekventovanějších termínů v námi zvoleném dokumentu z AJP, hlavní část našeho úkolu byla splněna.\n",
    "\n",
    "Abychom doložili svůj úspěch, náš výsledný jupyter notebook si vytiskneme do PDF (nabídka File -> Print) a nahrajeme na příslušné místo do Google Classroomu."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
